<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
	<link rel="manifest" href="./favicon/site.webmanifest">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<script>
		MathJax = {
			loader: { load: ['[tex]/textmacros'] },
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				packages: { '[+]': ['textmacros'] },
			},
		};
	</script>
	<script type="text/javascript" id="MathJax-script" async
		src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.min.js">
		</script>
	
		<link href="./_app/immutable/assets/0.08c9bd5d.css" rel="stylesheet">
		<link href="./_app/immutable/assets/3.15287e86.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.a239affa.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.e108d1fd.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons.6d736de4.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.6b10cb0e.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.38a092e6.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.627ff664.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/11.4ce1dbfc.js"><title>First Read - Teach LLMs to Personalize – An Approach inspired by Writing Education</title><!-- HEAD_svelte-r3s2wm_START --><!-- HEAD_svelte-r3s2wm_END -->
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents">  <div class="nav svelte-5baz1e" data-svelte-h="svelte-89nan6"><a href="/">Posts</a></div>  <div class="content svelte-lwo4ch"><div class="title svelte-lwo4ch" data-svelte-h="svelte-yw6qo2"><h1 class="svelte-lwo4ch">First Read</h1> <h2 class="svelte-lwo4ch">Teach LLMs to Personalize – An Approach inspired by Writing Education</h2> <div class="date svelte-lwo4ch">2023-08-20</div></div> <!-- HTML_TAG_START --><html><body><h2 id="overview">Overview</h2>
<p>LLM을 써서 할 수 있는 다양한 일들 중에 personalization이 필요한
일들이 있다. personalization이란 LLM의 응답을 customized된 응답으로
내보내는 것을 의미한다. 예를 들어, 어떤 작가와 똑같은 스타일로 문장을
쓴다거나, 한사람이 쓴 리뷰를 분석해 마치 그 사람이 쓴 것처럼 리뷰를
내놓는 식이다.</p>
<p><a href="#ref-li2023teach">[1]</a>은 writing education에서
영감을 받아 LLM을 personalization하는 새로운 방법을 제시하였다.</p>
<h2 id="problem-formulation">PROBLEM FORMULATION</h2>
<p>User가 document를 작성하고 있는 상황을 생각해보자. 이때, 작성중인
document를 <strong>current document</strong>, current document의 시작
부분(title이 있을 경우 합쳐서) 150자를 <strong>immediate
context</strong>라고 하자. 또 그 User가 과거에 작성한 document들을
<strong>personal context</strong>라고 하자.</p>
<p>Training task는 다음과 같이 나타낼 수 있다. <span class="math inline">\(x_{ut}\)</span>가 time step <span class="math inline">\(t\)</span>일 때 user <span class="math inline">\(u\)</span>의 current document <span class="math inline">\(d_{ut}\)</span>에 대한 immediate context이고 <span class="math inline">\(\mathcal{D}_{ut}=\{d_{u1}, d_{u2}, ...,
d_{u,t-1}\}\)</span>가 과거에 작성한 documents로 user <span class="math inline">\(u\)</span>의 personal context라고 하자. 우린
personalized generation model <span class="math inline">\(\mathbf{G}\)</span>를 학습시켜서 <span class="math inline">\((x_{ut}, \mathcal{D}_{ut})\)</span>를 input으로
받아 <span class="math inline">\(d'_{ut}\)</span>를 생성할 것이다.
이때 <span class="math inline">\(d'_{ut}\)</span>와 <span class="math inline">\(d_{ut}\)</span>의 유사도를 최대화하는 것이
목표이다. 앞으론 문맥상 명확할 때는 <span class="math inline">\(u\)</span>를 생략하고 <span class="math inline">\(x_t\)</span>, <span class="math inline">\(\mathcal{D}_{t}\)</span>, <span class="math inline">\(d_t\)</span>처럼 사용한다.</p>
<h2 id="method-overview">METHOD OVERVIEW</h2>
<figure id="fig:framework">
<img src="figures/teach-llms-to-personalize-an-approach-inspired-by-writing-education/framework.jpg" style="width:100.0%"/>
<figcaption>Figure 1: The overview of the multistage multitask framework
for personalized text generation. (Image source: Fig. 1 in <a href="#ref-li2023teach">[1]</a>)</figcaption>
</figure>
<p>기본적인 흐름은 Fig. <a data-reference="fig:framework" data-reference-type="ref" href="#fig:framework">1</a>와
같다.</p>
<ol>
<li><p>Retrieve: 먼저 Retriever <span class="math inline">\(\mathbf{Re}\)</span>로 immediate context <span class="math inline">\(x_t\)</span>를 query로 사용하여 <span class="math inline">\(\mathcal{D}_t\)</span>에서 document를
retrieve한다.</p></li>
<li><p>Rank: Ranker <span class="math inline">\(\mathbf{Ra}\)</span>를
이용하여 retrieved된 document들을 rank한다. 이 ranked entries를 <span class="math inline">\(\mathcal{E}_t\)</span>라고 하자.</p></li>
<li><p>Summarize: <span class="math inline">\(\mathcal{E}_t\)</span>를
summarization model <span class="math inline">\(\mathbf{Su}\)</span>에
넣어서 summary를 생성한다.</p></li>
<li><p>Synthesize: <span class="math inline">\(\mathcal{E}_t\)</span>를
synthesis model <span class="math inline">\(\mathbf{Sy}\)</span>에
넣어서 key element를 생성한다.</p></li>
<li><p>Generate: personalized generation model <span class="math inline">\(\mathbf{G}\)</span>를 이용하여 current document
<span class="math inline">\(d'_t\)</span>를 생성한다. 즉, <span class="math inline">\(d'_t = \mathbf{G}(x_t,
\mathbf{Su}(x_t,\mathcal{E}_{t}), \mathbf{Sy}(x_t,\mathcal{E}_{t}),
\mathcal{E}_{t})\)</span>.</p></li>
<li><p>Author Distinction: auxiliary task로, document <span class="math inline">\(d_{ui}\)</span>를 작성한 user <span class="math inline">\(u\)</span>와 다른 user가 작성한 document <span class="math inline">\(d_{vj}\)</span>를 pair로 묶어서 이를 구별할 수
있도록 <span class="math inline">\(\mathbf{G}\)</span>를 학습시킨다.
글쓴이를 구별하는 능력은 읽을때의 이해도가 높다는 뜻이기에 개인화된
문서를 쓸때에도 성능이 올라갈 것을 기대한 것이다.</p></li>
</ol>
<p>각 step에 대한 자세한 내용은 <a href="#ref-li2023teach">[1]</a>의 Section 5를 참고.</p>
<h2 id="result">Result</h2>
<p>실험은 총 3개의 dataset(Avocado Research Email Collection, Amazon
review data, Reddit comments dataset)을 이용하여 진행되었으며 모델은
T5-11B를 사용하였다. Metrics로는 <span class="smallcaps">Bleu</span>,
<span class="smallcaps">Rouge-1</span>, <span class="smallcaps">Rouge-2</span>, <span class="smallcaps">Rouge-L</span>가 사용되었다.</p>
<p>실험 결과, retrieval를 적용한 방식이 그렇지 않을때보다 좋은 성능을
보였으며, 이는 summarization과 synthesis 역시 마찬가지였다. Multitask
learning(author distinction 추가 학습)의 적용 역시 대부분의 경우 성능을
향상시켰다.</p>
<h2 id="quick-recap">Quick Recap</h2>
<ol>
<li><p>Retrieve, Rank, Summarize, Synthesize를 통해 personalized
generation의 성능을 높일 수 있다.</p></li>
<li><p>모델을 학습시킬 때, 추가 task로 author distinction을 학습시키면
성능이 더 높아진다.</p></li>
</ol>
<div class="references csl-bib-body hanging-indent" id="refs" role="list" style="margin-bottom: 2rem"><h2 style="margin-top: 4rem">References</h2>
<div class="csl-entry" id="ref-li2023teach" role="listitem">[1] 
Li, Cheng, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, Spurthi Amba
Hombaiah, Yi Liang, and Michael Bendersky. 2023. <span>“<a href="https://arxiv.org/abs/2308.07968">Teach LLMs to Personalize – an
Approach Inspired by Writing Education</a>.”</span>
</div>
</div>
</body></html><!-- HTML_TAG_END --> </div> 
			
			<script>
				{
					__sveltekit_12ay7ti = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,{"type":"data","data":{content:"\u003Chtml>\u003Cbody>\u003Ch2 id=\"overview\">Overview\u003C/h2>\n\u003Cp>LLM을 써서 할 수 있는 다양한 일들 중에 personalization이 필요한\n일들이 있다. personalization이란 LLM의 응답을 customized된 응답으로\n내보내는 것을 의미한다. 예를 들어, 어떤 작가와 똑같은 스타일로 문장을\n쓴다거나, 한사람이 쓴 리뷰를 분석해 마치 그 사람이 쓴 것처럼 리뷰를\n내놓는 식이다.\u003C/p>\n\u003Cp>\u003Ca href=\"#ref-li2023teach\">[1]\u003C/a>은 writing education에서\n영감을 받아 LLM을 personalization하는 새로운 방법을 제시하였다.\u003C/p>\n\u003Ch2 id=\"problem-formulation\">PROBLEM FORMULATION\u003C/h2>\n\u003Cp>User가 document를 작성하고 있는 상황을 생각해보자. 이때, 작성중인\ndocument를 \u003Cstrong>current document\u003C/strong>, current document의 시작\n부분(title이 있을 경우 합쳐서) 150자를 \u003Cstrong>immediate\ncontext\u003C/strong>라고 하자. 또 그 User가 과거에 작성한 document들을\n\u003Cstrong>personal context\u003C/strong>라고 하자.\u003C/p>\n\u003Cp>Training task는 다음과 같이 나타낼 수 있다. \u003Cspan class=\"math inline\">\\(x_{ut}\\)\u003C/span>가 time step \u003Cspan class=\"math inline\">\\(t\\)\u003C/span>일 때 user \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>의 current document \u003Cspan class=\"math inline\">\\(d_{ut}\\)\u003C/span>에 대한 immediate context이고 \u003Cspan class=\"math inline\">\\(\\mathcal{D}_{ut}=\\{d_{u1}, d_{u2}, ...,\nd_{u,t-1}\\}\\)\u003C/span>가 과거에 작성한 documents로 user \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>의 personal context라고 하자. 우린\npersonalized generation model \u003Cspan class=\"math inline\">\\(\\mathbf{G}\\)\u003C/span>를 학습시켜서 \u003Cspan class=\"math inline\">\\((x_{ut}, \\mathcal{D}_{ut})\\)\u003C/span>를 input으로\n받아 \u003Cspan class=\"math inline\">\\(d'_{ut}\\)\u003C/span>를 생성할 것이다.\n이때 \u003Cspan class=\"math inline\">\\(d'_{ut}\\)\u003C/span>와 \u003Cspan class=\"math inline\">\\(d_{ut}\\)\u003C/span>의 유사도를 최대화하는 것이\n목표이다. 앞으론 문맥상 명확할 때는 \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>를 생략하고 \u003Cspan class=\"math inline\">\\(x_t\\)\u003C/span>, \u003Cspan class=\"math inline\">\\(\\mathcal{D}_{t}\\)\u003C/span>, \u003Cspan class=\"math inline\">\\(d_t\\)\u003C/span>처럼 사용한다.\u003C/p>\n\u003Ch2 id=\"method-overview\">METHOD OVERVIEW\u003C/h2>\n\u003Cfigure id=\"fig:framework\">\n\u003Cimg src=\"figures/teach-llms-to-personalize-an-approach-inspired-by-writing-education/framework.jpg\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 1: The overview of the multistage multitask framework\nfor personalized text generation. (Image source: Fig. 1 in \u003Ca href=\"#ref-li2023teach\">[1]\u003C/a>)\u003C/figcaption>\n\u003C/figure>\n\u003Cp>기본적인 흐름은 Fig. \u003Ca data-reference=\"fig:framework\" data-reference-type=\"ref\" href=\"#fig:framework\">1\u003C/a>와\n같다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>Retrieve: 먼저 Retriever \u003Cspan class=\"math inline\">\\(\\mathbf{Re}\\)\u003C/span>로 immediate context \u003Cspan class=\"math inline\">\\(x_t\\)\u003C/span>를 query로 사용하여 \u003Cspan class=\"math inline\">\\(\\mathcal{D}_t\\)\u003C/span>에서 document를\nretrieve한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Rank: Ranker \u003Cspan class=\"math inline\">\\(\\mathbf{Ra}\\)\u003C/span>를\n이용하여 retrieved된 document들을 rank한다. 이 ranked entries를 \u003Cspan class=\"math inline\">\\(\\mathcal{E}_t\\)\u003C/span>라고 하자.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Summarize: \u003Cspan class=\"math inline\">\\(\\mathcal{E}_t\\)\u003C/span>를\nsummarization model \u003Cspan class=\"math inline\">\\(\\mathbf{Su}\\)\u003C/span>에\n넣어서 summary를 생성한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Synthesize: \u003Cspan class=\"math inline\">\\(\\mathcal{E}_t\\)\u003C/span>를\nsynthesis model \u003Cspan class=\"math inline\">\\(\\mathbf{Sy}\\)\u003C/span>에\n넣어서 key element를 생성한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Generate: personalized generation model \u003Cspan class=\"math inline\">\\(\\mathbf{G}\\)\u003C/span>를 이용하여 current document\n\u003Cspan class=\"math inline\">\\(d'_t\\)\u003C/span>를 생성한다. 즉, \u003Cspan class=\"math inline\">\\(d'_t = \\mathbf{G}(x_t,\n\\mathbf{Su}(x_t,\\mathcal{E}_{t}), \\mathbf{Sy}(x_t,\\mathcal{E}_{t}),\n\\mathcal{E}_{t})\\)\u003C/span>.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Author Distinction: auxiliary task로, document \u003Cspan class=\"math inline\">\\(d_{ui}\\)\u003C/span>를 작성한 user \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>와 다른 user가 작성한 document \u003Cspan class=\"math inline\">\\(d_{vj}\\)\u003C/span>를 pair로 묶어서 이를 구별할 수\n있도록 \u003Cspan class=\"math inline\">\\(\\mathbf{G}\\)\u003C/span>를 학습시킨다.\n글쓴이를 구별하는 능력은 읽을때의 이해도가 높다는 뜻이기에 개인화된\n문서를 쓸때에도 성능이 올라갈 것을 기대한 것이다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cp>각 step에 대한 자세한 내용은 \u003Ca href=\"#ref-li2023teach\">[1]\u003C/a>의 Section 5를 참고.\u003C/p>\n\u003Ch2 id=\"result\">Result\u003C/h2>\n\u003Cp>실험은 총 3개의 dataset(Avocado Research Email Collection, Amazon\nreview data, Reddit comments dataset)을 이용하여 진행되었으며 모델은\nT5-11B를 사용하였다. Metrics로는 \u003Cspan class=\"smallcaps\">Bleu\u003C/span>,\n\u003Cspan class=\"smallcaps\">Rouge-1\u003C/span>, \u003Cspan class=\"smallcaps\">Rouge-2\u003C/span>, \u003Cspan class=\"smallcaps\">Rouge-L\u003C/span>가 사용되었다.\u003C/p>\n\u003Cp>실험 결과, retrieval를 적용한 방식이 그렇지 않을때보다 좋은 성능을\n보였으며, 이는 summarization과 synthesis 역시 마찬가지였다. Multitask\nlearning(author distinction 추가 학습)의 적용 역시 대부분의 경우 성능을\n향상시켰다.\u003C/p>\n\u003Ch2 id=\"quick-recap\">Quick Recap\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cp>Retrieve, Rank, Summarize, Synthesize를 통해 personalized\ngeneration의 성능을 높일 수 있다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>모델을 학습시킬 때, 추가 task로 author distinction을 학습시키면\n성능이 더 높아진다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cdiv class=\"references csl-bib-body hanging-indent\" id=\"refs\" role=\"list\" style=\"margin-bottom: 2rem\">\u003Ch2 style=\"margin-top: 4rem\">References\u003C/h2>\n\u003Cdiv class=\"csl-entry\" id=\"ref-li2023teach\" role=\"listitem\">[1] \nLi, Cheng, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, Spurthi Amba\nHombaiah, Yi Liang, and Michael Bendersky. 2023. \u003Cspan>“\u003Ca href=\"https://arxiv.org/abs/2308.07968\">Teach LLMs to Personalize – an\nApproach Inspired by Writing Education\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003C/div>\n\u003C/body>\u003C/html>"},"uses":{}}];

					Promise.all([
						import("./_app/immutable/entry/start.a239affa.js"),
						import("./_app/immutable/entry/app.6b10cb0e.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 11],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>
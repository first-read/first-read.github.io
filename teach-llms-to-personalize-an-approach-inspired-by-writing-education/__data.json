{"type":"data","nodes":[null,{"type":"data","data":[{"content":1},"\u003Chtml>\u003Cbody>\u003Ch2 id=\"overview\">Overview\u003C/h2>\n\u003Cp>LLM을 써서 할 수 있는 다양한 일들 중에 personalization이 필요한\n일들이 있다. personalization이란 LLM의 응답을 customized된 응답으로\n내보내는 것을 의미한다. 예를 들어, 어떤 작가와 똑같은 스타일로 문장을\n쓴다거나, 한사람이 쓴 리뷰를 분석해 마치 그 사람이 쓴 것처럼 리뷰를\n내놓는 식이다.\u003C/p>\n\u003Cp>\u003Ca href=\"#ref-li2023teach\">[1]\u003C/a>은 writing education에서\n영감을 받아 LLM을 personalization하는 새로운 방법을 제시하였다.\u003C/p>\n\u003Ch2 id=\"problem-formulation\">PROBLEM FORMULATION\u003C/h2>\n\u003Cp>User가 document를 작성하고 있는 상황을 생각해보자. 이때, 작성중인\ndocument를 \u003Cstrong>current document\u003C/strong>, current document의 시작\n부분(title이 있을 경우 합쳐서) 150자를 \u003Cstrong>immediate\ncontext\u003C/strong>라고 하자. 또 그 User가 과거에 작성한 document들을\n\u003Cstrong>personal context\u003C/strong>라고 하자.\u003C/p>\n\u003Cp>Training task는 다음과 같이 나타낼 수 있다. \u003Cspan class=\"math inline\">\\(x_{ut}\\)\u003C/span>가 time step \u003Cspan class=\"math inline\">\\(t\\)\u003C/span>일 때 user \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>의 current document \u003Cspan class=\"math inline\">\\(d_{ut}\\)\u003C/span>에 대한 immediate context이고 \u003Cspan class=\"math inline\">\\(\\mathcal{D}_{ut}=\\{d_{u1}, d_{u2}, ...,\nd_{u,t-1}\\}\\)\u003C/span>가 과거에 작성한 documents로 user \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>의 personal context라고 하자. 우린\npersonalized generation model \u003Cspan class=\"math inline\">\\(\\mathbf{G}\\)\u003C/span>를 학습시켜서 \u003Cspan class=\"math inline\">\\((x_{ut}, \\mathcal{D}_{ut})\\)\u003C/span>를 input으로\n받아 \u003Cspan class=\"math inline\">\\(d'_{ut}\\)\u003C/span>를 생성할 것이다.\n이때 \u003Cspan class=\"math inline\">\\(d'_{ut}\\)\u003C/span>와 \u003Cspan class=\"math inline\">\\(d_{ut}\\)\u003C/span>의 유사도를 최대화하는 것이\n목표이다. 앞으론 문맥상 명확할 때는 \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>를 생략하고 \u003Cspan class=\"math inline\">\\(x_t\\)\u003C/span>, \u003Cspan class=\"math inline\">\\(\\mathcal{D}_{t}\\)\u003C/span>, \u003Cspan class=\"math inline\">\\(d_t\\)\u003C/span>처럼 사용한다.\u003C/p>\n\u003Ch2 id=\"method-overview\">METHOD OVERVIEW\u003C/h2>\n\u003Cfigure id=\"fig:framework\">\n\u003Cimg src=\"figures/teach-llms-to-personalize-an-approach-inspired-by-writing-education/framework.jpg\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 1: The overview of the multistage multitask framework\nfor personalized text generation. (Image source: Fig. 1 in \u003Ca href=\"#ref-li2023teach\">[1]\u003C/a>)\u003C/figcaption>\n\u003C/figure>\n\u003Cp>기본적인 흐름은 Fig. \u003Ca data-reference=\"fig:framework\" data-reference-type=\"ref\" href=\"#fig:framework\">1\u003C/a>와\n같다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>Retrieve: 먼저 Retriever \u003Cspan class=\"math inline\">\\(\\mathbf{Re}\\)\u003C/span>로 immediate context \u003Cspan class=\"math inline\">\\(x_t\\)\u003C/span>를 query로 사용하여 \u003Cspan class=\"math inline\">\\(\\mathcal{D}_t\\)\u003C/span>에서 document를\nretrieve한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Rank: Ranker \u003Cspan class=\"math inline\">\\(\\mathbf{Ra}\\)\u003C/span>를\n이용하여 retrieved된 document들을 rank한다. 이 ranked entries를 \u003Cspan class=\"math inline\">\\(\\mathcal{E}_t\\)\u003C/span>라고 하자.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Summarize: \u003Cspan class=\"math inline\">\\(\\mathcal{E}_t\\)\u003C/span>를\nsummarization model \u003Cspan class=\"math inline\">\\(\\mathbf{Su}\\)\u003C/span>에\n넣어서 summary를 생성한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Synthesize: \u003Cspan class=\"math inline\">\\(\\mathcal{E}_t\\)\u003C/span>를\nsynthesis model \u003Cspan class=\"math inline\">\\(\\mathbf{Sy}\\)\u003C/span>에\n넣어서 key element를 생성한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Generate: personalized generation model \u003Cspan class=\"math inline\">\\(\\mathbf{G}\\)\u003C/span>를 이용하여 current document\n\u003Cspan class=\"math inline\">\\(d'_t\\)\u003C/span>를 생성한다. 즉, \u003Cspan class=\"math inline\">\\(d'_t = \\mathbf{G}(x_t,\n\\mathbf{Su}(x_t,\\mathcal{E}_{t}), \\mathbf{Sy}(x_t,\\mathcal{E}_{t}),\n\\mathcal{E}_{t})\\)\u003C/span>.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Author Distinction: auxiliary task로, document \u003Cspan class=\"math inline\">\\(d_{ui}\\)\u003C/span>를 작성한 user \u003Cspan class=\"math inline\">\\(u\\)\u003C/span>와 다른 user가 작성한 document \u003Cspan class=\"math inline\">\\(d_{vj}\\)\u003C/span>를 pair로 묶어서 이를 구별할 수\n있도록 \u003Cspan class=\"math inline\">\\(\\mathbf{G}\\)\u003C/span>를 학습시킨다.\n글쓴이를 구별하는 능력은 읽을때의 이해도가 높다는 뜻이기에 개인화된\n문서를 쓸때에도 성능이 올라갈 것을 기대한 것이다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cp>각 step에 대한 자세한 내용은 \u003Ca href=\"#ref-li2023teach\">[1]\u003C/a>의 Section 5를 참고.\u003C/p>\n\u003Ch2 id=\"result\">Result\u003C/h2>\n\u003Cp>실험은 총 3개의 dataset(Avocado Research Email Collection, Amazon\nreview data, Reddit comments dataset)을 이용하여 진행되었으며 모델은\nT5-11B를 사용하였다. Metrics로는 \u003Cspan class=\"smallcaps\">Bleu\u003C/span>,\n\u003Cspan class=\"smallcaps\">Rouge-1\u003C/span>, \u003Cspan class=\"smallcaps\">Rouge-2\u003C/span>, \u003Cspan class=\"smallcaps\">Rouge-L\u003C/span>가 사용되었다.\u003C/p>\n\u003Cp>실험 결과, retrieval를 적용한 방식이 그렇지 않을때보다 좋은 성능을\n보였으며, 이는 summarization과 synthesis 역시 마찬가지였다. Multitask\nlearning(author distinction 추가 학습)의 적용 역시 대부분의 경우 성능을\n향상시켰다.\u003C/p>\n\u003Ch2 id=\"quick-recap\">Quick Recap\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cp>Retrieve, Rank, Summarize, Synthesize를 통해 personalized\ngeneration의 성능을 높일 수 있다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>모델을 학습시킬 때, 추가 task로 author distinction을 학습시키면\n성능이 더 높아진다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cdiv class=\"references csl-bib-body hanging-indent\" id=\"refs\" role=\"list\" style=\"margin-bottom: 2rem\">\u003Ch2 style=\"margin-top: 4rem\">References\u003C/h2>\n\u003Cdiv class=\"csl-entry\" id=\"ref-li2023teach\" role=\"listitem\">[1] \nLi, Cheng, Mingyang Zhang, Qiaozhu Mei, Yaqing Wang, Spurthi Amba\nHombaiah, Yi Liang, and Michael Bendersky. 2023. \u003Cspan>“\u003Ca href=\"https://arxiv.org/abs/2308.07968\">Teach LLMs to Personalize – an\nApproach Inspired by Writing Education\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003C/div>\n\u003C/body>\u003C/html>"],"uses":{}}]}

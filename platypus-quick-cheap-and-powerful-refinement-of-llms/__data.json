{"type":"data","nodes":[null,{"type":"data","data":[{"content":1},"\u003Chtml>\u003Cbody>\u003Ch2 id=\"overview\">Overview\u003C/h2>\n\u003Cp>최근의 LLM은 pre-trained model을 fine-tuning하여 다양한 task에 적용할\n수 있게 되었다. 하지만, 이런 fine-tuning 역시 많은 시간과 비용이\n소요된다. \u003Ca href=\"#ref-lee2023platypus\">[1]\u003C/a>에선 크지 않은\n사이즈의 high quality dataset을 curated하여 새로만든 dataset을 소개하고,\n이를 이용해 fine-tuning한 모델이 좋은 성능을 보임을 보인다.\u003C/p>\n\u003Ch2 id=\"methods\">Methods\u003C/h2>\n\u003Ch3 id=\"curating-open-platypus\">Curating Open-Platypus\u003C/h3>\n\u003Cp>\u003Cstrong>Open-Platypus\u003C/strong>는 논문에서 새로 만든 dataset이다.\n기존에 있던 11개의 오픈소스 dataset을 curate하여 만들었다. Dataset의\nquality를 높이기 위해 중복을 제거하고, test set의 오염도 체크를 통해\n데이터 오염을 방지하였다.\u003C/p>\n\u003Ch3 id=\"removing-similar-duplicate-questions\">Removing similar &amp;\nduplicate questions\u003C/h3>\n\u003Cp>Open-Platypus는 11개의 dataset을 합쳐 만든 dataset이기 때문에, 중복된\n질문이 많다. 이를 제거하기 위해 저자들은 질문의 유사도를 측정하고,\n유사도가 높은 질문을 제거하였다. 구체적인 과정은 다음과 같다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>Instruction이 완전히 같은 질문을 제거한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Instruction을 embedding을 거쳐 코사인 유사도를 측정하고, 80% 이상\n유사할 시 제거한다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cp>이때, 제거하는 data는 answer가 짧은쪽을 제거한다. answer가 긴 쪽이 더\n디테일한 설명을 담고있을 확률이 높기 때문이다.\u003C/p>\n\u003Ch3 id=\"contamination-check\">Contamination Check\u003C/h3>\n\u003Cfigure id=\"fig:duplicate\">\n\u003Cimg src=\"figures/platypus-quick-cheap-and-powerful-refinement-of-llms/fig1.png\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 1: Comparison of train and test questions in the\nduplicate contamination group. (Source: Fig. 1 in \u003Ca href=\"#ref-lee2023platypus\">[1]\u003C/a>)\u003C/figcaption>\n\u003C/figure>\n\u003Cp>벤치마크 측정을 위한 test set의 질문 등이 학습데이터 있을 경우,\n모델이 학습데이터를 기억하고 있을 수 있다. 이런 오염된 데이터로는 제대로\n벤치마크 측정을 할 수 없기에 데이터의 오염을 최대한 줄이는것 역시\n중요하다. 저자들은 이런 오염도 체크를 위해 의심되는 데이터를 다음 세가지\n경우로 나누어 체크하였다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Duplicate\u003C/strong>: Test set의 질문이 학습데이터의 질문과\n똑같거나, 질문에 속해있는 경우 Duplicate으로 분류하였다. Fig. \u003Ca data-reference=\"fig:duplicate\" data-reference-type=\"ref\" href=\"#fig:duplicate\">1\u003C/a>은 Duplicate으로 분류된 데이터의\n예시이다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Gray-area\u003C/strong>: 정확히 같진 않지만 유사한 질문을\nGray-area로 분류하였다. 질문이 같지만 answer가 다른(하지만 유사한) 경우\n등이 해당된다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Similar but different\u003C/strong>: 질문이 높은 코사인\n유사도를 보이지만 정답이 완전히 다른 경우이다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"fine-tuning-merging\">Fine-tuning &amp; merging\u003C/h3>\n\u003Cp>Full fine-tuning보다 비용을 낮추기 위해 LoRA를 사용하였다. 이때\n기존의 pre-trained모델의 학습데이터가 오염돼있을 수 있기때문에, 기존의\n모델에 merge를 할 때에는 오염돼있는 데이터로 학습된 모델을 피하였다.\nFine-tuning에 쓰인 구체적인 파라미터 설정은 Table \u003Ca data-reference=\"tab:hyperparams\" data-reference-type=\"ref\" href=\"#tab:hyperparams\">1\u003C/a>과 같다.\u003C/p>\n\u003Cfigure id=\"tab:hyperparams\">\n\u003Cimg src=\"figures/platypus-quick-cheap-and-powerful-refinement-of-llms/_13a1__table1.png\" style=\"width:100%;\"/>\n\u003Cfigcaption>\u003Cp>Table 1: Hyperparameters for 13B and 70B Models (Source: Table 2 in\n\u003Ca href=\"#ref-lee2023platypus\">[1]\u003C/a>)\u003C/p>\u003C/figcaption>\n\u003C/figure>\n\u003Ch2 id=\"results\">Results\u003C/h2>\n\u003Cp>결과는 Hugging Face Open LLM Leaderboard(8/10/23 기준)에서 다른\n모델들을 제치고 1위를 차지하였다. Fine-tuning 후의 성능은 Base 모델보다\n큰 향상을 보여주었다.\u003C/p>\n\u003Ch2 id=\"quick-recap\">Quick Recap\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Open-Platypus\u003C/strong>는 기존의 11개의 dataset을\ncurate하여 만든 dataset으로, 중복 질문 제거 등을 통해 데이터 quality를\n높였다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Data contamination check를 위한 방법으로, 의심되는 데이터를\n\u003Cstrong>Duplicate\u003C/strong>, \u003Cstrong>Gray-area\u003C/strong>, \u003Cstrong>Similar\nbut different\u003C/strong> 세가지로 나눠 체크할 수 있다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>이런 과정을 거친 high quality dataset과 LoRA같은 효율적인\nfine-tuning 방법을 이용하면 적은 비용으로 좋은 성능을 낼 수\n있다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cdiv class=\"references csl-bib-body hanging-indent\" id=\"refs\" role=\"list\" style=\"margin-bottom: 2rem\">\u003Ch2 style=\"margin-top: 4rem\">References\u003C/h2>\n\u003Cdiv class=\"csl-entry\" id=\"ref-lee2023platypus\" role=\"listitem\">[1] \nLee, Ariel N., Cole J. Hunter, and Nataniel Ruiz. 2023. \u003Cspan>“\u003Ca href=\"https://arxiv.org/abs/2308.07317\">Platypus: Quick, Cheap, and\nPowerful Refinement of LLMs\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003C/div>\n\u003C/body>\u003C/html>"],"uses":{}}]}

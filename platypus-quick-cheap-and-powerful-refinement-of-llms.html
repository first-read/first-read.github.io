<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
	<link rel="manifest" href="./favicon/site.webmanifest">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<script>
		MathJax = {
			loader: { load: ['[tex]/textmacros'] },
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				packages: { '[+]': ['textmacros'] },
			},
		};
	</script>
	<script type="text/javascript" id="MathJax-script" async
		src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.min.js">
		</script>
	
		<link href="./_app/immutable/assets/0.08c9bd5d.css" rel="stylesheet">
		<link href="./_app/immutable/assets/3.15287e86.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.63a02e9c.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.e108d1fd.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons.36d626ee.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.b8702bb8.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.38a092e6.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.0396fef1.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/9.adcdec8e.js"><title>First Read - Platypus: Quick, Cheap, and Powerful Refinement of LLMs</title><!-- HEAD_svelte-ivtdp2_START --><!-- HEAD_svelte-ivtdp2_END -->
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents">  <div class="nav svelte-5baz1e" data-svelte-h="svelte-89nan6"><a href="/">Posts</a></div>  <div class="content svelte-lwo4ch"><div class="title svelte-lwo4ch" data-svelte-h="svelte-83p6sg"><h1 class="svelte-lwo4ch">First Read</h1> <h2 class="svelte-lwo4ch">Platypus: Quick, Cheap, and Powerful Refinement of LLMs</h2> <div class="date svelte-lwo4ch">2023-09-03</div></div> <!-- HTML_TAG_START --><html><body><h2 id="overview">Overview</h2>
<p>최근의 LLM은 pre-trained model을 fine-tuning하여 다양한 task에 적용할
수 있게 되었다. 하지만, 이런 fine-tuning 역시 많은 시간과 비용이
소요된다. <a href="#ref-lee2023platypus">[1]</a>에선 기존의
datasets을 curate하여 만든 크지 않은 사이즈의 high quality dataset을
소개하고, 이를 이용해 fine-tuning 하는 방법을 제시한다. 그리고 이 방법을
통해 적은 비용으로 좋은 성능을 낼 수 있음을 보여준다.</p>
<h2 id="methods">Methods</h2>
<h3 id="curating-open-platypus">Curating Open-Platypus</h3>
<p><strong>Open-Platypus</strong>는 논문에서 새로 만든 dataset이다.
기존에 있던 11개의 오픈소스 dataset을 curate하여 만들었다. Dataset의
quality를 높이기 위해 중복을 제거하고, test set의 오염도 체크를 통해
데이터 오염을 방지하였다.</p>
<h3 id="removing-similar-duplicate-questions">Removing similar &amp;
duplicate questions</h3>
<p>Open-Platypus는 11개의 dataset을 합쳐 만든 dataset이기 때문에, 중복된
질문이 많다. 이를 제거하기 위해 저자들은 질문의 유사도를 측정하고,
유사도가 높은 질문을 제거하였다. 구체적인 과정은 다음과 같다.</p>
<ol>
<li><p>Instruction이 완전히 같은 질문을 제거한다.</p></li>
<li><p>Instruction을 embedding을 거쳐 코사인 유사도를 측정하고, 80% 이상
유사할 시 제거한다.</p></li>
</ol>
<p>이때, 제거하는 data는 answer가 짧은쪽을 제거한다. answer가 긴 쪽이 더
디테일한 설명을 담고있을 확률이 높기 때문이다.</p>
<h3 id="contamination-check">Contamination Check</h3>
<figure id="fig:duplicate">
<img src="figures/platypus-quick-cheap-and-powerful-refinement-of-llms/fig1.png" style="width:100.0%"/>
<figcaption>Figure 1: Comparison of train and test questions in the
duplicate contamination group. (Source: Fig. 1 in <a href="#ref-lee2023platypus">[1]</a>)</figcaption>
</figure>
<p>벤치마크 측정을 위한 test set의 질문 등이 학습데이터 있을 경우,
모델이 학습데이터를 기억하고 있을 수 있다. 이런 오염된 데이터로는 제대로
벤치마크 측정을 할 수 없기에 데이터의 오염을 최대한 줄이는것 역시
중요하다. 저자들은 이런 오염도 체크를 위해 의심되는 데이터를 다음 세가지
경우로 나누어 체크하였다.</p>
<ol>
<li><p><strong>Duplicate</strong>: Test set의 질문이 학습데이터의 질문과
똑같거나, 질문에 속해있는 경우 Duplicate으로 분류하였다. Fig. <a data-reference="fig:duplicate" data-reference-type="ref" href="#fig:duplicate">1</a>은 Duplicate으로 분류된 데이터의
예시이다.</p></li>
<li><p><strong>Gray-area</strong>: 정확히 같진 않지만 유사한 질문을
Gray-area로 분류하였다. 질문이 같지만 answer가 다른(하지만 유사한) 경우
등이 해당된다.</p></li>
<li><p><strong>Similar but different</strong>: 질문이 높은 코사인
유사도를 보이지만 정답이 완전히 다른 경우이다.</p></li>
</ol>
<h3 id="fine-tuning-merging">Fine-tuning &amp; merging</h3>
<p>Full fine-tuning보다 비용을 낮추기 위해 LoRA를 사용하였다. 이때
기존의 pre-trained모델의 학습데이터가 오염돼있을 수 있기때문에, 기존의
모델에 merge를 할 때에는 오염돼있는 데이터로 학습된 모델을 피하였다.
Fine-tuning에 쓰인 구체적인 파라미터 설정은 Table <a data-reference="tab:hyperparams" data-reference-type="ref" href="#tab:hyperparams">1</a>과 같다.</p>
<figure id="tab:hyperparams">
<img src="figures/platypus-quick-cheap-and-powerful-refinement-of-llms/_13a1__table1.png" style="width:100%;"/>
<figcaption><p>Table 1: Hyperparameters for 13B and 70B Models (Source: Table 2 in
<a href="#ref-lee2023platypus">[1]</a>)</p></figcaption>
</figure>
<h2 id="results">Results</h2>
<p>결과는 Hugging Face Open LLM Leaderboard(8/10/23 기준)에서 다른
모델들을 제치고 1위를 차지하였다. Fine-tuning 후의 성능은 Base 모델보다
큰 향상을 보여주었다.</p>
<h2 id="quick-recap">Quick Recap</h2>
<ol>
<li><p><strong>Open-Platypus</strong>는 기존 11개의 dataset을 curate하여
만든 dataset으로, 중복 질문 제거 등을 통해 데이터 quality를
높였다.</p></li>
<li><p>Data contamination check를 위한 방법으로, 의심되는 데이터를
<strong>Duplicate</strong>, <strong>Gray-area</strong>, <strong>Similar
but different</strong> 세가지로 나눠 체크할 수 있다.</p></li>
<li><p>이런 과정을 거친 high quality dataset과 LoRA같은 효율적인
fine-tuning 방법을 이용하면 적은 비용으로 좋은 성능을 낼 수
있다.</p></li>
</ol>
<div class="references csl-bib-body hanging-indent" id="refs" role="list" style="margin-bottom: 2rem"><h2 style="margin-top: 4rem">References</h2>
<div class="csl-entry" id="ref-lee2023platypus" role="listitem">[1] 
Lee, Ariel N., Cole J. Hunter, and Nataniel Ruiz. 2023. <span>“<a href="https://arxiv.org/abs/2308.07317">Platypus: Quick, Cheap, and
Powerful Refinement of LLMs</a>.”</span>
</div>
</div>
</body></html><!-- HTML_TAG_END --> </div> 
			
			<script>
				{
					__sveltekit_mtp1rx = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,{"type":"data","data":{content:"\u003Chtml>\u003Cbody>\u003Ch2 id=\"overview\">Overview\u003C/h2>\n\u003Cp>최근의 LLM은 pre-trained model을 fine-tuning하여 다양한 task에 적용할\n수 있게 되었다. 하지만, 이런 fine-tuning 역시 많은 시간과 비용이\n소요된다. \u003Ca href=\"#ref-lee2023platypus\">[1]\u003C/a>에선 기존의\ndatasets을 curate하여 만든 크지 않은 사이즈의 high quality dataset을\n소개하고, 이를 이용해 fine-tuning 하는 방법을 제시한다. 그리고 이 방법을\n통해 적은 비용으로 좋은 성능을 낼 수 있음을 보여준다.\u003C/p>\n\u003Ch2 id=\"methods\">Methods\u003C/h2>\n\u003Ch3 id=\"curating-open-platypus\">Curating Open-Platypus\u003C/h3>\n\u003Cp>\u003Cstrong>Open-Platypus\u003C/strong>는 논문에서 새로 만든 dataset이다.\n기존에 있던 11개의 오픈소스 dataset을 curate하여 만들었다. Dataset의\nquality를 높이기 위해 중복을 제거하고, test set의 오염도 체크를 통해\n데이터 오염을 방지하였다.\u003C/p>\n\u003Ch3 id=\"removing-similar-duplicate-questions\">Removing similar &amp;\nduplicate questions\u003C/h3>\n\u003Cp>Open-Platypus는 11개의 dataset을 합쳐 만든 dataset이기 때문에, 중복된\n질문이 많다. 이를 제거하기 위해 저자들은 질문의 유사도를 측정하고,\n유사도가 높은 질문을 제거하였다. 구체적인 과정은 다음과 같다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>Instruction이 완전히 같은 질문을 제거한다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Instruction을 embedding을 거쳐 코사인 유사도를 측정하고, 80% 이상\n유사할 시 제거한다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cp>이때, 제거하는 data는 answer가 짧은쪽을 제거한다. answer가 긴 쪽이 더\n디테일한 설명을 담고있을 확률이 높기 때문이다.\u003C/p>\n\u003Ch3 id=\"contamination-check\">Contamination Check\u003C/h3>\n\u003Cfigure id=\"fig:duplicate\">\n\u003Cimg src=\"figures/platypus-quick-cheap-and-powerful-refinement-of-llms/fig1.png\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 1: Comparison of train and test questions in the\nduplicate contamination group. (Source: Fig. 1 in \u003Ca href=\"#ref-lee2023platypus\">[1]\u003C/a>)\u003C/figcaption>\n\u003C/figure>\n\u003Cp>벤치마크 측정을 위한 test set의 질문 등이 학습데이터 있을 경우,\n모델이 학습데이터를 기억하고 있을 수 있다. 이런 오염된 데이터로는 제대로\n벤치마크 측정을 할 수 없기에 데이터의 오염을 최대한 줄이는것 역시\n중요하다. 저자들은 이런 오염도 체크를 위해 의심되는 데이터를 다음 세가지\n경우로 나누어 체크하였다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Duplicate\u003C/strong>: Test set의 질문이 학습데이터의 질문과\n똑같거나, 질문에 속해있는 경우 Duplicate으로 분류하였다. Fig. \u003Ca data-reference=\"fig:duplicate\" data-reference-type=\"ref\" href=\"#fig:duplicate\">1\u003C/a>은 Duplicate으로 분류된 데이터의\n예시이다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Gray-area\u003C/strong>: 정확히 같진 않지만 유사한 질문을\nGray-area로 분류하였다. 질문이 같지만 answer가 다른(하지만 유사한) 경우\n등이 해당된다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Similar but different\u003C/strong>: 질문이 높은 코사인\n유사도를 보이지만 정답이 완전히 다른 경우이다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Ch3 id=\"fine-tuning-merging\">Fine-tuning &amp; merging\u003C/h3>\n\u003Cp>Full fine-tuning보다 비용을 낮추기 위해 LoRA를 사용하였다. 이때\n기존의 pre-trained모델의 학습데이터가 오염돼있을 수 있기때문에, 기존의\n모델에 merge를 할 때에는 오염돼있는 데이터로 학습된 모델을 피하였다.\nFine-tuning에 쓰인 구체적인 파라미터 설정은 Table \u003Ca data-reference=\"tab:hyperparams\" data-reference-type=\"ref\" href=\"#tab:hyperparams\">1\u003C/a>과 같다.\u003C/p>\n\u003Cfigure id=\"tab:hyperparams\">\n\u003Cimg src=\"figures/platypus-quick-cheap-and-powerful-refinement-of-llms/_13a1__table1.png\" style=\"width:100%;\"/>\n\u003Cfigcaption>\u003Cp>Table 1: Hyperparameters for 13B and 70B Models (Source: Table 2 in\n\u003Ca href=\"#ref-lee2023platypus\">[1]\u003C/a>)\u003C/p>\u003C/figcaption>\n\u003C/figure>\n\u003Ch2 id=\"results\">Results\u003C/h2>\n\u003Cp>결과는 Hugging Face Open LLM Leaderboard(8/10/23 기준)에서 다른\n모델들을 제치고 1위를 차지하였다. Fine-tuning 후의 성능은 Base 모델보다\n큰 향상을 보여주었다.\u003C/p>\n\u003Ch2 id=\"quick-recap\">Quick Recap\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Open-Platypus\u003C/strong>는 기존 11개의 dataset을 curate하여\n만든 dataset으로, 중복 질문 제거 등을 통해 데이터 quality를\n높였다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Data contamination check를 위한 방법으로, 의심되는 데이터를\n\u003Cstrong>Duplicate\u003C/strong>, \u003Cstrong>Gray-area\u003C/strong>, \u003Cstrong>Similar\nbut different\u003C/strong> 세가지로 나눠 체크할 수 있다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>이런 과정을 거친 high quality dataset과 LoRA같은 효율적인\nfine-tuning 방법을 이용하면 적은 비용으로 좋은 성능을 낼 수\n있다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cdiv class=\"references csl-bib-body hanging-indent\" id=\"refs\" role=\"list\" style=\"margin-bottom: 2rem\">\u003Ch2 style=\"margin-top: 4rem\">References\u003C/h2>\n\u003Cdiv class=\"csl-entry\" id=\"ref-lee2023platypus\" role=\"listitem\">[1] \nLee, Ariel N., Cole J. Hunter, and Nataniel Ruiz. 2023. \u003Cspan>“\u003Ca href=\"https://arxiv.org/abs/2308.07317\">Platypus: Quick, Cheap, and\nPowerful Refinement of LLMs\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003C/div>\n\u003C/body>\u003C/html>"},"uses":{}}];

					Promise.all([
						import("./_app/immutable/entry/start.63a02e9c.js"),
						import("./_app/immutable/entry/app.b8702bb8.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 9],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>
<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<link rel="apple-touch-icon" sizes="180x180" href="./favicon/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="./favicon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="./favicon/favicon-16x16.png">
	<link rel="manifest" href="./favicon/site.webmanifest">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<script>
		MathJax = {
			loader: { load: ['[tex]/textmacros'] },
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				packages: { '[+]': ['textmacros'] },
			},
		};
	</script>
	<script type="text/javascript" id="MathJax-script" async
		src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.min.js">
		</script>
	
		<link href="./_app/immutable/assets/0.08c9bd5d.css" rel="stylesheet">
		<link href="./_app/immutable/assets/3.15287e86.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.4df507bb.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/scheduler.e108d1fd.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/singletons.1c92cb9c.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.fe26990b.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/index.38a092e6.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.552ed64b.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/12.437c1dde.js"><title>First Read - Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification</title><!-- HEAD_svelte-zl16ev_START --><!-- HEAD_svelte-zl16ev_END -->
</head>

<body data-sveltekit-preload-data="hover">
	<div style="display: contents">  <div class="nav svelte-5baz1e" data-svelte-h="svelte-89nan6"><a href="/">Posts</a></div>  <div class="content svelte-lwo4ch"><div class="title svelte-lwo4ch" data-svelte-h="svelte-1dr857n"><h1 class="svelte-lwo4ch">First Read</h1> <h2 class="svelte-lwo4ch">Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification</h2> <div class="date svelte-lwo4ch">2023-08-17</div></div> <!-- HTML_TAG_START --><html><body><h2 id="overview">Overview</h2>
<p>LLM은 프롬프팅, 외부 프로그램과 연결(예를 들어, code execution) 등
여러 방법을 통해 더 좋은 성능을 얻을 수 있다. OpenAI의
<em>GPT4-Code</em>는 Python과 연결된 GPT4로 파이썬 code를 실행할 수 있고
그 결과를 LLM과 주고받으며 기존의 GPT-4 보다 더 높은 성능을
보여준다.<br/>
특히 이와 같은 LLM의 code와의 상호작용은 code를 통해 정확한 계산 등을 할
수 있다는 점에서 LLM의 수학문제에 대한 성능 향상에 도움을 준다.<br/>
<a href="#ref-zhou2023solving">[2]</a>에선 실제로 code
사용이 얼마나 수학문제에 대한 성능(정확도) 향상에 도움을 주는지를
확인하고 이를 활용해 더욱 성능을 높일 수 있는 방법을 제시하였다.</p>
<h2 id="method">Method</h2>
<p>실험은 크게 두 부분으로 나뉘며 모두 GPT4-Code를 이용하였다.</p>
<ol>
<li><p>code의 사용이 얼마나 도움이 되는지 알아보는 pilot
experiment</p></li>
<li><p>주 실험으로</p>
<ol>
<li><p><strong>explicit code-based self-verification</strong>(CSV)이라는
기법을 적용한 실험</p></li>
<li><p>CSV에 <strong>verification-guided weighted majority
voting</strong>이라는 기법을 함께 적용한 실험</p></li>
</ol></li>
</ol>
<h2 id="pilot-experiment">Pilot Experiment</h2>
<p>Code의 사용이 얼마나 도움이 되는지 알아보기 위해, <a href="#ref-zhou2023solving">[2]</a>에선 여러
프롬프트로 비교분석을 진행하였다.</p>
<ol>
<li><p><strong>Prompt1</strong>: <em>No code usage is allowed</em>: code
사용을 허용하지 않는 프롬프트</p></li>
<li><p><strong>Prompt2</strong>: <em>Code can be used only once</em>:
한번의 code 사용을 허용하는 프롬프트</p></li>
<li><p><strong>Basic Prompt</strong>: Code 사용에 제한을 두지 않음. 기본
프롬프트</p></li>
</ol>
<figure id="fig:code_acc">
<img src="figures/solving-challenging-math-word-problems-using-gpt-4-code-interpreter-with-code-based-self-verification/fig_code_acc.jpg" style="width:100.0%"/>
<figcaption>Figure 1: Performance on MATH dataset of different levels by
applying different prompts to adjust the frequency of code usage.
<strong>(a)</strong> Comparison of overall accuracy between the 4
prompts. <strong>(b)</strong> Code usage frequency is in proportion to
accuracy in all five levels and this phenomenon is especially apparent
when the problems are relatively complicated  (i.e. with higher level).
(Image source: Fig. 2 in <a href="#ref-zhou2023solving">[2]</a>)</figcaption>
</figure>
<p>실험 결과, <strong>Basic Prompt</strong> &gt;
<strong>Prompt2</strong> &gt; <strong>Prompt1</strong> 순으로 높은
정확도를 보였다(Fig <a data-reference="fig:code_acc" data-reference-type="ref" href="#fig:code_acc">1</a>). 즉, code 사용 빈도가(논문에선
<em>Code Usage Frequency</em>라고 표현하였다.) 더 높을수록 더 높은
정확도를 보였다.</p>
<p>저자들은 관찰된 다음의 두가지 특성이 이를 가능케 한다고 보았다.</p>
<ol>
<li><p>자연어 추론 단계를 여러번씩 짧게 나눠 code와 같이 쓰면 정확도가
높아지는 경향이 있다.</p></li>
<li><p>언어모델 자체적으로 code execution의 결과를 평가하고 이를
바탕으로 solution을 수정할 능력이 있다.</p></li>
</ol>
<h2 id="explicit-code-based-self-verification-prompting">Explicit
Code-based Self-verification Prompting</h2>
<p>Pilot experiment의 관찰을 바탕으로 저자들은 <strong>explicit
code-based self-verification</strong>(CSV)이라는 새 기법을
제안하였다.</p>
<p>모델의 솔루션을 <span class="math inline">\(\mathbf{C}\)</span>라
할때, 이를 code를 통해 검증하는 verification stage <span class="math inline">\(\mathbf{V}\)</span>를 추가한다. <span class="math inline">\(\mathbf{V}\)</span>는 <em>True</em>,
<em>False</em>, <em>Uncertain</em> 세가지 값 중 하나를 가진다. 전체적인
동작은 다음과 같다.</p>
<p><span><span class="math display">\[\mathbf{C} \rightarrow
\mathbf{V}=\begin{cases}
    \text{True}      &amp; \rightarrow \text{final
answer}                                                                                                      \\
    \text{False}     &amp; \rightarrow \mathbf{C}_{\text{new}}
\rightarrow \mathbf{V} \rightarrow \dots \rightarrow \text{True}
\rightarrow \text{final answer} \\
    \text{Uncertain} &amp; \rightarrow \text{final answer}
  \end{cases}\qquad{(1)}\]</span></span></p>
<p>즉, 모델이 내놓은 솔루션을 검증하여 <em>True</em>나
<em>Uncertain</em>일 경우 그대로 답을 내고, <em>False</em>일 경우 이
검증을 바탕으로 솔루션을 수정하여 다시 이 절차를 반복한다. 이때 검증과
수정은 code-based인 것이 특징이다.</p>
<h2 id="verification-guided-weighted-majority-voting">Verification-guided
Weighted Majority Voting</h2>
<p>Fig. <a data-reference="fig:code_acc" data-reference-type="ref" href="#fig:code_acc">1</a>에서 볼 수 있듯이, CSV 기법은 기존
성능을 크게 앞질렀다. 저자들은 이에 그치지 않고 CSV기법에 voting을
추가로 적용하였다. 이는 <a href="#ref-wang2023selfconsistency">[1]</a>에서
제시된 self-consistency CoT와 비슷한 방법으로, 여러번의 솔루션과 그
검증결과를 바탕으로 투표를 통해 최종 답을 결정하는 것이다. 이때, 검증
결과가 <strong>True</strong>일 경우 더 정답에 가깝다고 신뢰할 수
있으므로 더 높은 가중치를 주는 식으로 voting을 진행한다. 자세한 방법은
다음과 같다.</p>
<p>검증 결과 <strong>True</strong>, <strong>Uncertain</strong>,
<strong>False</strong> 각각의 투표 가중치를 <span class="math inline">\(w_\mathbf{\scriptscriptstyle{T}},
w_\mathbf{{\scriptscriptstyle{U}}}\)</span>, <span class="math inline">\(w_\mathbf{{\scriptscriptstyle{F}}}\)</span>라
하자.<br/>
이때, 모델이 생성한 <span class="math inline">\(k\)</span>개의 출력에
대해 <span class="math inline">\(i\left(= 1, 2, \ldots,
k\right)\)</span>번째 답을 <span class="math inline">\(a^i\)</span>,
대응되는 검증 결과를 <span class="math inline">\(v^i\)</span>라 하면 각
답안 후보 <span class="math inline">\(a\)</span>에 대한 voting score
함수를 다음과 같이 정의할 수 있다.</p>
<p><span><span class="math display">\[\text{Score}(a) = \sum_{\{v\}} w_v
(\#\{i \mid  a^{i}=a~ \text{and} ~ v^{i}=v\}), \quad v\in\{\text{True},
\text{Uncertain}, \text{False}\}\qquad{(2)}\]</span></span></p>
<p>최종적으로 가장 높은 score를 받은 답을 최종 답으로 선택한다. 즉,
<span><span class="math display">\[\text{Output} = \arg\max_{a}
\text{Score}(a)\qquad{(3)}\]</span></span> 이때 <span class="math inline">\(w_\mathbf{\scriptscriptstyle{T}} &gt;
w_\mathbf{{\scriptscriptstyle{U}}} \geq
w_\mathbf{{\scriptscriptstyle{F}}}\)</span>으로 가중치를 설정하여야
한다.</p>
<p>Fig. <a data-reference="fig:method" data-reference-type="ref" href="#fig:method">2</a>는 이 과정을 그림으로 나타낸
것이다.</p>
<figure id="fig:method">
<img src="figures/solving-challenging-math-word-problems-using-gpt-4-code-interpreter-with-code-based-self-verification/fig_method.jpg" style="width:100.0%"/>
<figcaption>Figure 2: <strong>(a)</strong> Illustration of the Naive
majority voting <a href="#ref-wang2023selfconsistency">[1]</a>
and Verification-guided weighted majority voting. <strong>(b)</strong>
The full pipeline of the proposed Verification-guided Weighted Majority
Voting framework. (Image source: Fig. 4 in <a href="#ref-zhou2023solving">[2]</a>) </figcaption>
</figure>
<h2 id="result">Result</h2>
<p>MATH dataset의 경우, GPT4-Code는 69.69%, GPT4-Code + CSV는 73.54%,
GPT4-Code + CSV + voting은 84.32%로 정확도가 향상되는 모습을 보였다.
다만 문제 카테고리별로 향상정도가 달랐다. 특히, Geometry 같은 경우 0.6%
정도의 향상만 있었다.</p>
<h3 id="miscellaneous">Miscellaneous</h3>
<ol>
<li><p>GSM8K, MMLU dataset에서의 실험 역시 모두 GPT4-Code + CSV +
voting이 가장 높은 정확도를 보였다.</p></li>
<li><p>문제의 카테고리, 난이도에 상관없이 Code Usage Frequency가
높을수록 높은 정확도를 보였다.</p></li>
<li><p>Verification stage를 자연어로 진행한 경우 오히려 <em>Basic
Prompt</em>보다 정확도가 살짝 떨어졌다.</p></li>
<li><p>검증 결과와 실제 답에 대한 confusion matrix를 보면 정확도보다
정밀도가 크게 높은 것을 볼 수 있다. 즉, 검증 결과가
<strong>True</strong>일 경우 실제 답이 <strong>True</strong>일 확률이
높다는 것으로, 최종답을 내기전에 <strong>True</strong>에 도달하기만
한다면 더 높은 정확도를 얻을 수 있을 것이다.</p></li>
<li><p>Voting에서 검증결과의 가중치 세팅은 <span class="math inline">\(w_\mathbf{\scriptscriptstyle{T}} &gt;
w_\mathbf{{\scriptscriptstyle{U}}} \geq
w_\mathbf{{\scriptscriptstyle{F}}}\)</span> 만 만족하면 된다. 다른
세팅의 경우, 단순한 naive majority voting(모두 동일 가중치)보다도 성능이
떨어지는 경우가 있었다.</p></li>
</ol>
<h2 id="quick-recap">Quick Recap</h2>
<ol>
<li><p>code 사용 빈도가 높을수록 정확도가 높아진다.</p></li>
<li><p>Verification stage를 추가하고 code로 검증하면 정확도가 더
높아진다.</p></li>
<li><p>검증 결과를 바탕으로 weighted voting을 하면 정확도가 더
높아진다.</p></li>
</ol>
<div class="references csl-bib-body hanging-indent" id="refs" role="list" style="margin-bottom: 2rem"><h2 style="margin-top: 4rem">References</h2>
<div class="csl-entry" id="ref-wang2023selfconsistency" role="listitem">[1] 
Wang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan
Narang, Aakanksha Chowdhery, and Denny Zhou. 2023. <span>“<a href="https://openreview.net/forum?id=1PL1NIMMrw">Self-Consistency
Improves Chain of Thought Reasoning in Language Models</a>.”</span>
</div>
<div class="csl-entry" id="ref-zhou2023solving" role="listitem">[2] 
Zhou, Aojun, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin,
Shaoqing Lu, et al. 2023. <span>“<a href="https://arxiv.org/abs/2308.07921">Solving Challenging Math Word
Problems Using GPT-4 Code Interpreter with Code-Based
Self-Verification</a>.”</span>
</div>
</div>
</body></html><!-- HTML_TAG_END --> </div> 
			
			<script>
				{
					__sveltekit_cu4vx4 = {
						base: new URL(".", location).pathname.slice(0, -1),
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,{"type":"data","data":{content:"\u003Chtml>\u003Cbody>\u003Ch2 id=\"overview\">Overview\u003C/h2>\n\u003Cp>LLM은 프롬프팅, 외부 프로그램과 연결(예를 들어, code execution) 등\n여러 방법을 통해 더 좋은 성능을 얻을 수 있다. OpenAI의\n\u003Cem>GPT4-Code\u003C/em>는 Python과 연결된 GPT4로 파이썬 code를 실행할 수 있고\n그 결과를 LLM과 주고받으며 기존의 GPT-4 보다 더 높은 성능을\n보여준다.\u003Cbr/>\n특히 이와 같은 LLM의 code와의 상호작용은 code를 통해 정확한 계산 등을 할\n수 있다는 점에서 LLM의 수학문제에 대한 성능 향상에 도움을 준다.\u003Cbr/>\n\u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>에선 실제로 code\n사용이 얼마나 수학문제에 대한 성능(정확도) 향상에 도움을 주는지를\n확인하고 이를 활용해 더욱 성능을 높일 수 있는 방법을 제시하였다.\u003C/p>\n\u003Ch2 id=\"method\">Method\u003C/h2>\n\u003Cp>실험은 크게 두 부분으로 나뉘며 모두 GPT4-Code를 이용하였다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>code의 사용이 얼마나 도움이 되는지 알아보는 pilot\nexperiment\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>주 실험으로\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>explicit code-based self-verification\u003C/strong>(CSV)이라는\n기법을 적용한 실험\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>CSV에 \u003Cstrong>verification-guided weighted majority\nvoting\u003C/strong>이라는 기법을 함께 적용한 실험\u003C/p>\u003C/li>\n\u003C/ol>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"pilot-experiment\">Pilot Experiment\u003C/h2>\n\u003Cp>Code의 사용이 얼마나 도움이 되는지 알아보기 위해, \u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>에선 여러\n프롬프트로 비교분석을 진행하였다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Prompt1\u003C/strong>: \u003Cem>No code usage is allowed\u003C/em>: code\n사용을 허용하지 않는 프롬프트\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Prompt2\u003C/strong>: \u003Cem>Code can be used only once\u003C/em>:\n한번의 code 사용을 허용하는 프롬프트\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Basic Prompt\u003C/strong>: Code 사용에 제한을 두지 않음. 기본\n프롬프트\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cfigure id=\"fig:code_acc\">\n\u003Cimg src=\"figures/solving-challenging-math-word-problems-using-gpt-4-code-interpreter-with-code-based-self-verification/fig_code_acc.jpg\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 1: Performance on MATH dataset of different levels by\napplying different prompts to adjust the frequency of code usage.\n\u003Cstrong>(a)\u003C/strong> Comparison of overall accuracy between the 4\nprompts. \u003Cstrong>(b)\u003C/strong> Code usage frequency is in proportion to\naccuracy in all five levels and this phenomenon is especially apparent\nwhen the problems are relatively complicated  (i.e. with higher level).\n(Image source: Fig. 2 in \u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>)\u003C/figcaption>\n\u003C/figure>\n\u003Cp>실험 결과, \u003Cstrong>Basic Prompt\u003C/strong> &gt;\n\u003Cstrong>Prompt2\u003C/strong> &gt; \u003Cstrong>Prompt1\u003C/strong> 순으로 높은\n정확도를 보였다(Fig \u003Ca data-reference=\"fig:code_acc\" data-reference-type=\"ref\" href=\"#fig:code_acc\">1\u003C/a>). 즉, code 사용 빈도가(논문에선\n\u003Cem>Code Usage Frequency\u003C/em>라고 표현하였다.) 더 높을수록 더 높은\n정확도를 보였다.\u003C/p>\n\u003Cp>저자들은 관찰된 다음의 두가지 특성이 이를 가능케 한다고 보았다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>자연어 추론 단계를 여러번씩 짧게 나눠 code와 같이 쓰면 정확도가\n높아지는 경향이 있다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>언어모델 자체적으로 code execution의 결과를 평가하고 이를\n바탕으로 solution을 수정할 능력이 있다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"explicit-code-based-self-verification-prompting\">Explicit\nCode-based Self-verification Prompting\u003C/h2>\n\u003Cp>Pilot experiment의 관찰을 바탕으로 저자들은 \u003Cstrong>explicit\ncode-based self-verification\u003C/strong>(CSV)이라는 새 기법을\n제안하였다.\u003C/p>\n\u003Cp>모델의 솔루션을 \u003Cspan class=\"math inline\">\\(\\mathbf{C}\\)\u003C/span>라\n할때, 이를 code를 통해 검증하는 verification stage \u003Cspan class=\"math inline\">\\(\\mathbf{V}\\)\u003C/span>를 추가한다. \u003Cspan class=\"math inline\">\\(\\mathbf{V}\\)\u003C/span>는 \u003Cem>True\u003C/em>,\n\u003Cem>False\u003C/em>, \u003Cem>Uncertain\u003C/em> 세가지 값 중 하나를 가진다. 전체적인\n동작은 다음과 같다.\u003C/p>\n\u003Cp>\u003Cspan>\u003Cspan class=\"math display\">\\[\\mathbf{C} \\rightarrow\n\\mathbf{V}=\\begin{cases}\n    \\text{True}      &amp; \\rightarrow \\text{final\nanswer}                                                                                                      \\\\\n    \\text{False}     &amp; \\rightarrow \\mathbf{C}_{\\text{new}}\n\\rightarrow \\mathbf{V} \\rightarrow \\dots \\rightarrow \\text{True}\n\\rightarrow \\text{final answer} \\\\\n    \\text{Uncertain} &amp; \\rightarrow \\text{final answer}\n  \\end{cases}\\qquad{(1)}\\]\u003C/span>\u003C/span>\u003C/p>\n\u003Cp>즉, 모델이 내놓은 솔루션을 검증하여 \u003Cem>True\u003C/em>나\n\u003Cem>Uncertain\u003C/em>일 경우 그대로 답을 내고, \u003Cem>False\u003C/em>일 경우 이\n검증을 바탕으로 솔루션을 수정하여 다시 이 절차를 반복한다. 이때 검증과\n수정은 code-based인 것이 특징이다.\u003C/p>\n\u003Ch2 id=\"verification-guided-weighted-majority-voting\">Verification-guided\nWeighted Majority Voting\u003C/h2>\n\u003Cp>Fig. \u003Ca data-reference=\"fig:code_acc\" data-reference-type=\"ref\" href=\"#fig:code_acc\">1\u003C/a>에서 볼 수 있듯이, CSV 기법은 기존\n성능을 크게 앞질렀다. 저자들은 이에 그치지 않고 CSV기법에 voting을\n추가로 적용하였다. 이는 \u003Ca href=\"#ref-wang2023selfconsistency\">[1]\u003C/a>에서\n제시된 self-consistency CoT와 비슷한 방법으로, 여러번의 솔루션과 그\n검증결과를 바탕으로 투표를 통해 최종 답을 결정하는 것이다. 이때, 검증\n결과가 \u003Cstrong>True\u003C/strong>일 경우 더 정답에 가깝다고 신뢰할 수\n있으므로 더 높은 가중치를 주는 식으로 voting을 진행한다. 자세한 방법은\n다음과 같다.\u003C/p>\n\u003Cp>검증 결과 \u003Cstrong>True\u003C/strong>, \u003Cstrong>Uncertain\u003C/strong>,\n\u003Cstrong>False\u003C/strong> 각각의 투표 가중치를 \u003Cspan class=\"math inline\">\\(w_\\mathbf{\\scriptscriptstyle{T}},\nw_\\mathbf{{\\scriptscriptstyle{U}}}\\)\u003C/span>, \u003Cspan class=\"math inline\">\\(w_\\mathbf{{\\scriptscriptstyle{F}}}\\)\u003C/span>라\n하자.\u003Cbr/>\n이때, 모델이 생성한 \u003Cspan class=\"math inline\">\\(k\\)\u003C/span>개의 출력에\n대해 \u003Cspan class=\"math inline\">\\(i\\left(= 1, 2, \\ldots,\nk\\right)\\)\u003C/span>번째 답을 \u003Cspan class=\"math inline\">\\(a^i\\)\u003C/span>,\n대응되는 검증 결과를 \u003Cspan class=\"math inline\">\\(v^i\\)\u003C/span>라 하면 각\n답안 후보 \u003Cspan class=\"math inline\">\\(a\\)\u003C/span>에 대한 voting score\n함수를 다음과 같이 정의할 수 있다.\u003C/p>\n\u003Cp>\u003Cspan>\u003Cspan class=\"math display\">\\[\\text{Score}(a) = \\sum_{\\{v\\}} w_v\n(\\#\\{i \\mid  a^{i}=a~ \\text{and} ~ v^{i}=v\\}), \\quad v\\in\\{\\text{True},\n\\text{Uncertain}, \\text{False}\\}\\qquad{(2)}\\]\u003C/span>\u003C/span>\u003C/p>\n\u003Cp>최종적으로 가장 높은 score를 받은 답을 최종 답으로 선택한다. 즉,\n\u003Cspan>\u003Cspan class=\"math display\">\\[\\text{Output} = \\arg\\max_{a}\n\\text{Score}(a)\\qquad{(3)}\\]\u003C/span>\u003C/span> 이때 \u003Cspan class=\"math inline\">\\(w_\\mathbf{\\scriptscriptstyle{T}} &gt;\nw_\\mathbf{{\\scriptscriptstyle{U}}} \\geq\nw_\\mathbf{{\\scriptscriptstyle{F}}}\\)\u003C/span>으로 가중치를 설정하여야\n한다.\u003C/p>\n\u003Cp>Fig. \u003Ca data-reference=\"fig:method\" data-reference-type=\"ref\" href=\"#fig:method\">2\u003C/a>는 이 과정을 그림으로 나타낸\n것이다.\u003C/p>\n\u003Cfigure id=\"fig:method\">\n\u003Cimg src=\"figures/solving-challenging-math-word-problems-using-gpt-4-code-interpreter-with-code-based-self-verification/fig_method.jpg\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 2: \u003Cstrong>(a)\u003C/strong> Illustration of the Naive\nmajority voting \u003Ca href=\"#ref-wang2023selfconsistency\">[1]\u003C/a>\nand Verification-guided weighted majority voting. \u003Cstrong>(b)\u003C/strong>\nThe full pipeline of the proposed Verification-guided Weighted Majority\nVoting framework. (Image source: Fig. 4 in \u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>) \u003C/figcaption>\n\u003C/figure>\n\u003Ch2 id=\"result\">Result\u003C/h2>\n\u003Cp>MATH dataset의 경우, GPT4-Code는 69.69%, GPT4-Code + CSV는 73.54%,\nGPT4-Code + CSV + voting은 84.32%로 정확도가 향상되는 모습을 보였다.\n다만 문제 카테고리별로 향상정도가 달랐다. 특히, Geometry 같은 경우 0.6%\n정도의 향상만 있었다.\u003C/p>\n\u003Ch3 id=\"miscellaneous\">Miscellaneous\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cp>GSM8K, MMLU dataset에서의 실험 역시 모두 GPT4-Code + CSV +\nvoting이 가장 높은 정확도를 보였다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>문제의 카테고리, 난이도에 상관없이 Code Usage Frequency가\n높을수록 높은 정확도를 보였다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Verification stage를 자연어로 진행한 경우 오히려 \u003Cem>Basic\nPrompt\u003C/em>보다 정확도가 살짝 떨어졌다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>검증 결과와 실제 답에 대한 confusion matrix를 보면 정확도보다\n정밀도가 크게 높은 것을 볼 수 있다. 즉, 검증 결과가\n\u003Cstrong>True\u003C/strong>일 경우 실제 답이 \u003Cstrong>True\u003C/strong>일 확률이\n높다는 것으로, 최종답을 내기전에 \u003Cstrong>True\u003C/strong>에 도달하기만\n한다면 더 높은 정확도를 얻을 수 있을 것이다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Voting에서 검증결과의 가중치 세팅은 \u003Cspan class=\"math inline\">\\(w_\\mathbf{\\scriptscriptstyle{T}} &gt;\nw_\\mathbf{{\\scriptscriptstyle{U}}} \\geq\nw_\\mathbf{{\\scriptscriptstyle{F}}}\\)\u003C/span> 만 만족하면 된다. 다른\n세팅의 경우, 단순한 naive majority voting(모두 동일 가중치)보다도 성능이\n떨어지는 경우가 있었다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"quick-recap\">Quick Recap\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cp>code 사용 빈도가 높을수록 정확도가 높아진다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Verification stage를 추가하고 code로 검증하면 정확도가 더\n높아진다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>검증 결과를 바탕으로 weighted voting을 하면 정확도가 더\n높아진다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cdiv class=\"references csl-bib-body hanging-indent\" id=\"refs\" role=\"list\" style=\"margin-bottom: 2rem\">\u003Ch2 style=\"margin-top: 4rem\">References\u003C/h2>\n\u003Cdiv class=\"csl-entry\" id=\"ref-wang2023selfconsistency\" role=\"listitem\">[1] \nWang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan\nNarang, Aakanksha Chowdhery, and Denny Zhou. 2023. \u003Cspan>“\u003Ca href=\"https://openreview.net/forum?id=1PL1NIMMrw\">Self-Consistency\nImproves Chain of Thought Reasoning in Language Models\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003Cdiv class=\"csl-entry\" id=\"ref-zhou2023solving\" role=\"listitem\">[2] \nZhou, Aojun, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin,\nShaoqing Lu, et al. 2023. \u003Cspan>“\u003Ca href=\"https://arxiv.org/abs/2308.07921\">Solving Challenging Math Word\nProblems Using GPT-4 Code Interpreter with Code-Based\nSelf-Verification\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003C/div>\n\u003C/body>\u003C/html>"},"uses":{}}];

					Promise.all([
						import("./_app/immutable/entry/start.4df507bb.js"),
						import("./_app/immutable/entry/app.fe26990b.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 12],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
</body>

</html>
{"type":"data","nodes":[null,{"type":"data","data":[{"content":1},"\u003Chtml>\u003Cbody>\u003Ch2 id=\"overview\">Overview\u003C/h2>\n\u003Cp>LLM은 프롬프팅, 외부 프로그램과 연결(예를 들어, code execution) 등\n여러 방법을 통해 더 좋은 성능을 얻을 수 있다. OpenAI의\n\u003Cem>GPT4-Code\u003C/em>는 Python과 연결된 GPT4로 파이썬 code를 실행할 수 있고\n그 결과를 LLM과 주고받으며 기존의 GPT-4 보다 더 높은 성능을\n보여준다.\u003Cbr/>\n특히 이와 같은 LLM의 code와의 상호작용은 code를 통해 정확한 계산 등을 할\n수 있다는 점에서 LLM의 수학문제에 대한 성능 향상에 도움을 준다.\u003Cbr/>\n\u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>에선 실제로 code\n사용이 얼마나 수학문제에 대한 성능(정확도) 향상에 도움을 주는지를\n확인하고 이를 활용해 더욱 성능을 높일 수 있는 방법을 제시하였다.\u003C/p>\n\u003Ch2 id=\"method\">Method\u003C/h2>\n\u003Cp>실험은 크게 두 부분으로 나뉘며 모두 GPT4-Code를 이용하였다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>code의 사용이 얼마나 도움이 되는지 알아보는 pilot\nexperiment\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>주 실험으로\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>explicit code-based self-verification\u003C/strong>(CSV)이라는\n기법을 적용한 실험\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>CSV에 \u003Cstrong>verification-guided weighted majority\nvoting\u003C/strong>이라는 기법을 함께 적용한 실험\u003C/p>\u003C/li>\n\u003C/ol>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"pilot-experiment\">Pilot Experiment\u003C/h2>\n\u003Cp>Code의 사용이 얼마나 도움이 되는지 알아보기 위해, \u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>에선 여러\n프롬프트로 비교분석을 진행하였다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>\u003Cstrong>Prompt1\u003C/strong>: \u003Cem>No code usage is allowed\u003C/em>: code\n사용을 허용하지 않는 프롬프트\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Prompt2\u003C/strong>: \u003Cem>Code can be used only once\u003C/em>:\n한번의 code 사용을 허용하는 프롬프트\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>\u003Cstrong>Basic Prompt\u003C/strong>: Code 사용에 제한을 두지 않음. 기본\n프롬프트\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cfigure id=\"fig:code_acc\">\n\u003Cimg src=\"figures/solving-challenging-math-word-problems-using-gpt-4-code-interpreter-with-code-based-self-verification/fig_code_acc.jpg\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 1: Performance on MATH dataset of different levels by\napplying different prompts to adjust the frequency of code usage.\n\u003Cstrong>(a)\u003C/strong> Comparison of overall accuracy between the 4\nprompts. \u003Cstrong>(b)\u003C/strong> Code usage frequency is in proportion to\naccuracy in all five levels and this phenomenon is especially apparent\nwhen the problems are relatively complicated  (i.e. with higher level).\n(Image source: Fig. 2 in \u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>)\u003C/figcaption>\n\u003C/figure>\n\u003Cp>실험 결과, \u003Cspan class=\"math inline\">\\(\\textbf{Basic Prompt} &gt;\n\\textbf{Prompt2} &gt; \\textbf{Prompt1}\\)\u003C/span> 순으로 높은 정확도를\n보였다(Fig \u003Ca data-reference=\"fig:code_acc\" data-reference-type=\"ref\" href=\"#fig:code_acc\">1\u003C/a>). 즉, code 사용 빈도가(논문에선\n\u003Cem>Code Usage Frequency\u003C/em>라고 표현하였다.) 더 높을수록 더 높은\n정확도를 보였다.\u003C/p>\n\u003Cp>저자들은 관찰된 다음의 두가지 특성이 이를 가능케 한다고 보았다.\u003C/p>\n\u003Col>\n\u003Cli>\u003Cp>자연어 추론 단계를 여러번씩 짧게 나눠 code와 같이 쓰면 정확도가\n높아지는 경향이 있다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>언어모델 자체적으로 code execution의 결과를 평가하고 이를\n바탕으로 solution을 수정할 능력이 있다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"explicit-code-based-self-verification-prompting\">Explicit\nCode-based Self-verification Prompting\u003C/h2>\n\u003Cp>Pilot experiment의 관찰을 바탕으로 저자들은 \u003Cstrong>explicit\ncode-based self-verification\u003C/strong>(CSV)이라는 새 기법을\n제안하였다.\u003C/p>\n\u003Cp>모델의 솔루션을 \u003Cspan class=\"math inline\">\\(\\mathbf{C}\\)\u003C/span>라\n할때, 이를 code를 통해 검증하는 verification stage \u003Cspan class=\"math inline\">\\(\\mathbf{V}\\)\u003C/span>를 추가한다. \u003Cspan class=\"math inline\">\\(\\mathbf{V}\\)\u003C/span>는 \u003Cem>True\u003C/em>,\n\u003Cem>False\u003C/em>, \u003Cem>Uncertain\u003C/em> 세가지 값 중 하나를 가진다. 전체적인\n동작은 다음과 같다.\u003C/p>\n\u003Cp>\u003Cspan>\u003Cspan class=\"math display\">\\[\\mathbf{C} \\rightarrow\n\\mathbf{V}=\\begin{cases}\n    \\text{True}      &amp; \\rightarrow \\text{final\nanswer}                                                                                                      \\\\\n    \\text{False}     &amp; \\rightarrow \\mathbf{C}_{\\text{new}}\n\\rightarrow \\mathbf{V} \\rightarrow \\dots \\rightarrow \\text{True}\n\\rightarrow \\text{final answer} \\\\\n    \\text{Uncertain} &amp; \\rightarrow \\text{final answer}\n  \\end{cases}\\qquad{(1)}\\]\u003C/span>\u003C/span>\u003C/p>\n\u003Cp>즉, 모델이 내놓은 솔루션을 검증하여 \u003Cem>True\u003C/em>나\n\u003Cem>Uncertain\u003C/em>일 경우 그대로 답을 내고, \u003Cem>False\u003C/em>일 경우 이\n검증을 바탕으로 솔루션을 수정하여 다시 이 절차를 반복한다. 이때 검증과\n수정은 code-based인 것이 특징이다.\u003C/p>\n\u003Ch2 id=\"verification-guided-weighted-majority-voting\">Verification-guided\nWeighted Majority Voting\u003C/h2>\n\u003Cp>Fig. \u003Ca data-reference=\"fig:code_acc\" data-reference-type=\"ref\" href=\"#fig:code_acc\">1\u003C/a>에서 볼 수 있듯이, CSV 기법은 기존\n성능을 크게 앞질렀다. 저자들은 이에 그치지 않고 CSV기법에 voting을\n추가로 적용하였다. 이는 \u003Ca href=\"#ref-wang2023selfconsistency\">[1]\u003C/a>에서\n제시된 self-consistency CoT와 비슷한 방법으로, 여러번의 솔루션과 그\n검증결과를 바탕으로 투표를 통해 최종 답을 결정하는 것이다. 이때, 검증\n결과가 \u003Cstrong>True\u003C/strong>일 경우 더 정답에 가깝다고 신뢰할 수\n있으므로 더 높은 가중치를 주는 식으로 voting을 진행한다. 자세한 방법은\n다음과 같다.\u003C/p>\n\u003Cp>검증 결과 \u003Cstrong>True\u003C/strong>, \u003Cstrong>Uncertain\u003C/strong>,\n\u003Cstrong>False\u003C/strong> 각각의 투표 가중치를 \u003Cspan class=\"math inline\">\\(w_\\mathbf{\\scriptscriptstyle{T}},\nw_\\mathbf{{\\scriptscriptstyle{U}}}\\)\u003C/span>, \u003Cspan class=\"math inline\">\\(w_\\mathbf{{\\scriptscriptstyle{F}}}\\)\u003C/span>라\n하자.\u003Cbr/>\n이때, 모델이 생성한 \u003Cspan class=\"math inline\">\\(k\\)\u003C/span>개의 출력에\n대해 \u003Cspan class=\"math inline\">\\(i\\left(= 1, 2, \\ldots,\nk\\right)\\)\u003C/span>번째 답을 \u003Cspan class=\"math inline\">\\(a^i\\)\u003C/span>,\n대응되는 검증 결과를 \u003Cspan class=\"math inline\">\\(v^i\\)\u003C/span>라 하면 각\n답안 후보 \u003Cspan class=\"math inline\">\\(a\\)\u003C/span>에 대한 voting score\n함수를 다음과 같이 정의할 수 있다.\u003C/p>\n\u003Cp>\u003Cspan>\u003Cspan class=\"math display\">\\[\\text{Score}(a) = \\sum_{\\{v\\}} w_v\n(\\#\\{i \\mid  a^{i}=a~ \\text{and} ~ v^{i}=v\\}), \\quad v\\in\\{\\text{True},\n\\text{Uncertain}, \\text{False}\\}\\qquad{(2)}\\]\u003C/span>\u003C/span>\u003C/p>\n\u003Cp>최종적으로 가장 높은 score를 받은 답을 최종 답으로 선택한다. 즉,\n\u003Cspan>\u003Cspan class=\"math display\">\\[\\text{Output} = \\arg\\max_{a}\n\\text{Score}(a)\\qquad{(3)}\\]\u003C/span>\u003C/span> 이때 \u003Cspan class=\"math inline\">\\(w_\\mathbf{\\scriptscriptstyle{T}} &gt;\nw_\\mathbf{{\\scriptscriptstyle{U}}} \\geq\nw_\\mathbf{{\\scriptscriptstyle{F}}}\\)\u003C/span>으로 가중치를 설정하여야\n한다.\u003C/p>\n\u003Cp>Fig. \u003Ca data-reference=\"fig:method\" data-reference-type=\"ref\" href=\"#fig:method\">2\u003C/a>는 이 과정을 그림으로 나타낸\n것이다.\u003C/p>\n\u003Cfigure id=\"fig:method\">\n\u003Cimg src=\"figures/solving-challenging-math-word-problems-using-gpt-4-code-interpreter-with-code-based-self-verification/fig_method.jpg\" style=\"width:100.0%\"/>\n\u003Cfigcaption>Figure 2: \u003Cstrong>(a)\u003C/strong> Illustration of the Naive\nmajority voting \u003Ca href=\"#ref-wang2023selfconsistency\">[1]\u003C/a>\nand Verification-guided weighted majority voting. \u003Cstrong>(b)\u003C/strong>\nThe full pipeline of the proposed Verification-guided Weighted Majority\nVoting framework. (Image source: Fig. 4 in \u003Ca href=\"#ref-zhou2023solving\">[2]\u003C/a>) \u003C/figcaption>\n\u003C/figure>\n\u003Ch2 id=\"result\">Result\u003C/h2>\n\u003Cp>MATH dataset의 경우, GPT4-Code는 69.69%, GPT4-Code + CSV는 73.54%,\nGPT4-Code + CSV + voting은 84.32%로 정확도가 향상되는 모습을 보였다.\n다만 문제 카테고리별로 향상정도가 달랐다. 특히, Geometry 같은 경우 0.6%\n정도의 향상만 있었다.\u003C/p>\n\u003Ch3 id=\"miscellaneous\">Miscellaneous\u003C/h3>\n\u003Col>\n\u003Cli>\u003Cp>GSM8K, MMLU dataset에서의 실험 역시 모두 GPT4-Code + CSV +\nvoting이 가장 높은 정확도를 보였다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>문제의 카테고리, 난이도에 상관없이 Code Usage Frequency가\n높을수록 높은 정확도를 보였다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Verification stage를 자연어로 진행한 경우 오히려 \u003Cem>Basic\nPrompt\u003C/em>보다 정확도가 살짝 떨어졌다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>검증 결과와 실제 답에 대한 confusion matrix를 보면 정확도보다\n정밀도가 크게 높은 것을 볼 수 있다. 즉, 검증 결과가\n\u003Cstrong>True\u003C/strong>일 경우 실제 답이 \u003Cstrong>True\u003C/strong>일 확률이\n높다는 것으로, 최종답을 내기전에 \u003Cstrong>True\u003C/strong>에 도달하기만\n한다면 더 높은 정확도를 얻을 수 있을 것이다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Voting에서 검증결과의 가중치 세팅은 \u003Cspan class=\"math inline\">\\(w_\\mathbf{\\scriptscriptstyle{T}} &gt;\nw_\\mathbf{{\\scriptscriptstyle{U}}} \\geq\nw_\\mathbf{{\\scriptscriptstyle{F}}}\\)\u003C/span> 만 만족하면 된다. 다른\n세팅의 경우, 단순한 naive majority voting(모두 동일 가중치)보다도 성능이\n떨어지는 경우가 있었다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Ch2 id=\"quick-recap\">Quick Recap\u003C/h2>\n\u003Col>\n\u003Cli>\u003Cp>code 사용 빈도가 높을수록 정확도가 높아진다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>Verification stage를 추가하고 code로 검증하면 정확도가 더\n높아진다.\u003C/p>\u003C/li>\n\u003Cli>\u003Cp>검증 결과를 바탕으로 weighted voting을 하면 정확도가 더\n높아진다.\u003C/p>\u003C/li>\n\u003C/ol>\n\u003Cdiv class=\"references csl-bib-body hanging-indent\" id=\"refs\" role=\"list\" style=\"margin-bottom: 2rem\">\u003Ch2 style=\"margin-top: 4rem\">References\u003C/h2>\n\u003Cdiv class=\"csl-entry\" id=\"ref-wang2023selfconsistency\" role=\"listitem\">[1] \nWang, Xuezhi, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan\nNarang, Aakanksha Chowdhery, and Denny Zhou. 2023. \u003Cspan>“\u003Ca href=\"https://openreview.net/forum?id=1PL1NIMMrw\">Self-Consistency\nImproves Chain of Thought Reasoning in Language Models\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003Cdiv class=\"csl-entry\" id=\"ref-zhou2023solving\" role=\"listitem\">[2] \nZhou, Aojun, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin,\nShaoqing Lu, et al. 2023. \u003Cspan>“\u003Ca href=\"https://arxiv.org/abs/2308.07921\">Solving Challenging Math Word\nProblems Using GPT-4 Code Interpreter with Code-Based\nSelf-Verification\u003C/a>.”\u003C/span>\n\u003C/div>\n\u003C/div>\n\u003C/body>\u003C/html>"],"uses":{}}]}
